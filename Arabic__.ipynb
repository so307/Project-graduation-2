{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd8d61cf-8a72-40a1-acb7-6cf54fb7eabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\s7r_2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\s7r_2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Data preprocessing important libraries\n",
    "import pandas as pd  #Data manipulation\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pickle  \n",
    "import nltk  #Natural language processing \n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords  #Stop word removal\n",
    "from nltk.tokenize import word_tokenize  #Tokenizition\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import pyarabic.araby as araby\n",
    "import qalsadi.lemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from nltk.util import ngrams\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string  #Remove punctuation & characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f59c865-7307-4a3c-994f-a3d6e8866629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>رقم  التصنيف</th>\n",
       "      <th>صنف الخبر</th>\n",
       "      <th>عنوان الخبر</th>\n",
       "      <th>clean</th>\n",
       "      <th>cleaned_stopwords</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>صحة</td>\n",
       "      <td>الجلوس أكثر من 10 ساعات يومياً يفاقم مخاطر الوفاة</td>\n",
       "      <td>الجلوس اكثر من  ساعات يومياً يفاقم مخاطر الوفاه</td>\n",
       "      <td>الجلوس اكثر ساعات يوميا يفاقم مخاطر الوفاه</td>\n",
       "      <td>[('جلوس', 'noun'), ('كثر', 'verb'), ('ساعة', '...</td>\n",
       "      <td>جلوس كثر ساعة يوم فاقم مخاطر الوفاه</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>رياضة</td>\n",
       "      <td>مولر: هناك طريقة واحدة لإيقاف خطورة ميسي</td>\n",
       "      <td>مولر هناك طريقه واحده لايقاف خطوره ميسي</td>\n",
       "      <td>مولر طريقه واحده لايقاف خطوره ميسي</td>\n",
       "      <td>[('مولر', 'all'), ('طريق', 'noun'), ('واحد', '...</td>\n",
       "      <td>مولر طريق واحد لايقاف خطوره ميس</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>اقتصاد</td>\n",
       "      <td>وزير مالية لبنان: \"إجراءات تقشفية استثنائية\" ب...</td>\n",
       "      <td>وزير ماليه لبنان اجراءات تقشفيه استثنائيه بموا...</td>\n",
       "      <td>وزير ماليه لبنان اجراءات تقشفيه استثنائيه بموازنه</td>\n",
       "      <td>[('زير', 'noun'), ('مال', 'noun'), ('لبن', 'no...</td>\n",
       "      <td>زير مال لبن اجراءات تقشف استثناء موازن</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>فن</td>\n",
       "      <td>مروان خوري: هكذا أقضي فترة الحجر المنزلي</td>\n",
       "      <td>مروان خوري هكذا اقضي فتره الحجر المنزلي</td>\n",
       "      <td>مروان خوري اقضي فتره الحجر المنزلي</td>\n",
       "      <td>[('مرو', 'noun'), ('خور', 'noun'), ('قضى', 've...</td>\n",
       "      <td>مرو خور قضى فتر حجر منزل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>اقتصاد</td>\n",
       "      <td>مصر تبدأ حملة التطعيم بلقاح كورونا لعامة الشعب</td>\n",
       "      <td>مصر تبدا حمله التطعيم بلقاح كورونا لعامه الشعب</td>\n",
       "      <td>مصر تبدا حمله التطعيم بلقاح كورونا لعامه الشعب</td>\n",
       "      <td>[('مصر', 'noun'), ('بد', 'verb'), ('حمل', 'nou...</td>\n",
       "      <td>مصر بد حمل تطعيم لقاح كار عام شعب</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   رقم  التصنيف صنف الخبر                                        عنوان الخبر  \\\n",
       "0             0       صحة  الجلوس أكثر من 10 ساعات يومياً يفاقم مخاطر الوفاة   \n",
       "1             5     رياضة           مولر: هناك طريقة واحدة لإيقاف خطورة ميسي   \n",
       "2             6    اقتصاد  وزير مالية لبنان: \"إجراءات تقشفية استثنائية\" ب...   \n",
       "3             4        فن           مروان خوري: هكذا أقضي فترة الحجر المنزلي   \n",
       "4             6    اقتصاد     مصر تبدأ حملة التطعيم بلقاح كورونا لعامة الشعب   \n",
       "\n",
       "                                               clean  \\\n",
       "0    الجلوس اكثر من  ساعات يومياً يفاقم مخاطر الوفاه   \n",
       "1            مولر هناك طريقه واحده لايقاف خطوره ميسي   \n",
       "2  وزير ماليه لبنان اجراءات تقشفيه استثنائيه بموا...   \n",
       "3            مروان خوري هكذا اقضي فتره الحجر المنزلي   \n",
       "4     مصر تبدا حمله التطعيم بلقاح كورونا لعامه الشعب   \n",
       "\n",
       "                                   cleaned_stopwords  \\\n",
       "0         الجلوس اكثر ساعات يوميا يفاقم مخاطر الوفاه   \n",
       "1                 مولر طريقه واحده لايقاف خطوره ميسي   \n",
       "2  وزير ماليه لبنان اجراءات تقشفيه استثنائيه بموازنه   \n",
       "3                 مروان خوري اقضي فتره الحجر المنزلي   \n",
       "4     مصر تبدا حمله التطعيم بلقاح كورونا لعامه الشعب   \n",
       "\n",
       "                                     lemmatized_text  \\\n",
       "0  [('جلوس', 'noun'), ('كثر', 'verb'), ('ساعة', '...   \n",
       "1  [('مولر', 'all'), ('طريق', 'noun'), ('واحد', '...   \n",
       "2  [('زير', 'noun'), ('مال', 'noun'), ('لبن', 'no...   \n",
       "3  [('مرو', 'noun'), ('خور', 'noun'), ('قضى', 've...   \n",
       "4  [('مصر', 'noun'), ('بد', 'verb'), ('حمل', 'nou...   \n",
       "\n",
       "                               lemmatized  \n",
       "0     جلوس كثر ساعة يوم فاقم مخاطر الوفاه  \n",
       "1         مولر طريق واحد لايقاف خطوره ميس  \n",
       "2  زير مال لبن اجراءات تقشف استثناء موازن  \n",
       "3                مرو خور قضى فتر حجر منزل  \n",
       "4       مصر بد حمل تطعيم لقاح كار عام شعب  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = pd.read_excel(r'C:\\Users\\s7r_2\\Downloads\\��تصنيف الاخبار العربيه - نسخة.xlsx')\n",
    "text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "927ab02c-f826-4419-aab8-54978e5b6e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words:\n",
      "[('علي', 6489), ('ال', 3774), ('؟', 3062), ('مصر', 2942), ('كار', 2832), ('جديد', 2719), ('السعوديه', 2183), ('مليار', 1774), ('عالم', 1580), ('ب', 1295), ('سبب', 1269), ('اقتصاد', 1237), ('عام', 1205), ('مليون', 1096), ('دب', 1092), ('دور', 1074), ('طير', 1043), ('سب', 1003), ('ايران', 924), ('الامارات', 924), ('اميركا', 922), ('شهر', 879), ('بريطاني', 872), ('تطبيق', 870), ('امام', 861), ('صور', 839), ('ترمب', 823), ('خلال', 822), ('اتحاد', 818), ('سعودي', 790), ('ترك', 778), ('لصى', 776), ('بلا', 772), ('اتفاق', 765), ('لقاح', 753), ('فن', 745), ('اول', 742), ('طلق', 740), ('توقع', 738), ('يوم', 732), ('عراق', 727), ('رئيس', 717), ('حذر', 703), ('عمل', 697), ('علن', 688), ('دعم', 676), ('عرب', 660), ('سياح', 651), ('استثمار', 629), ('تعرف', 619), ('ل', 617), ('دول', 613), ('رحلة', 612), ('هاتف', 607), ('فيروس', 598), ('قطاع', 595), ('نمو', 593), ('مطار', 592), ('كثر', 579), ('لاعب', 579), ('زير', 575), ('عبر', 573), ('تراجع', 570), ('نظام', 567), ('حول', 564), ('ايفون', 563), ('مهرج', 561), ('كشف', 557), ('السياحه', 552), ('سرطان', 549), ('فا', 549), ('العالميه', 548), ('محمد', 547), ('فوز', 546), ('صندوق', 546), ('غوغل', 542), ('لبن', 541), ('خط', 538), ('تكشف', 537), ('دولي', 537), ('مرض', 515), ('مواجه', 512), ('بحث', 509), ('شركة', 505), ('اصابه', 503), ('فيديو', 501), ('فضل', 499), ('كبر', 496), ('ضد', 492), ('لفا', 488), ('الصحه', 484), ('روس', 477), ('برشلونه', 477), ('قلب', 472), ('حال', 460), ('اوروبا', 457), ('نصر', 457), ('سوري', 455), ('ألام', 452), ('الاوروبي', 447), ('كويت', 447), ('يمن', 442), ('طائر', 436), ('علاج', 433), ('منتخب', 432), ('سفر', 430), ('تويتر', 428), ('ان', 427), ('دراس', 427), ('عمر', 421), ('ارتفاع', 420), ('وجه', 417), ('مركز', 415), ('تجار', 415), ('رفض', 414), ('هذا', 413), ('نهائي', 410), ('مدرب', 409), ('خطر', 408), ('ليبي', 407), ('هذه', 406), ('رمض', 403), ('عاد', 402), ('حرب', 399), ('مدريد', 397), ('عرض', 394), ('نقد', 390), ('ميز', 389), ('تاريخ', 386), ('شاهد', 385), ('خفض', 380), ('خليج', 379), ('هواتف', 379), ('سنوات', 378), ('حساب', 377), ('مغرب', 375), ('طالب', 374), ('استعاد', 365), ('الاميركيه', 365), ('الرياض', 363), ('مال', 362), ('هلال', 362), ('حمد', 359), ('ميس', 358), ('عود', 355), ('بد', 352), ('زمه', 351), ('رفع', 351), ('كاسي', 350), ('مستخدم', 349), ('قتل', 349), ('فرنسا', 345), ('لماذا', 344), ('شرك', 340), ('تونس', 340), ('مر', 336), ('بن', 336), ('مسافر', 336), ('طريق', 334), ('ربع', 334), ('نصف', 334), ('جد', 333), ('شباب', 327), ('طلب', 327), ('حت', 325), ('سي', 325), ('نجوم', 325), ('التجاره', 324), ('سينما', 322), ('المصريه', 322), ('المانيا', 319), ('نقل', 317), ('زياد', 317), ('مسؤول', 317), ('الاول', 315), ('مقتل', 314), ('موسم', 313), ('العربيه', 312), ('ثاني', 312), ('داعش', 311), ('يونايتد', 310), ('شخص', 310), ('مباراه', 309), ('واتساب', 308), ('صحة', 308), ('عملة', 307), ('أكد', 305), ('بكور', 305), ('قدم', 304), ('هزم', 302), ('عبد', 301), ('اندرويد', 300), ('أعاد', 300), ('ابوظبي', 299), ('حمل', 298), ('ضرب', 297), ('الاصابه', 295), ('تفاصيل', 292), ('الاطفال', 292), ('فتح', 292)]\n",
      "Least common words:\n",
      "[('توجود', 1), ('مضيء', 1), ('فلح', 1), ('للدعايه', 1), ('نافالكارنيرو', 1), ('بالخطه', 1), ('الشاحنه', 1), ('تومسونهيراه', 1), ('بالحريه', 1), ('واغلاقه', 1), ('بوديسكو', 1), ('والمولوديه', 1), ('واتضامن', 1), ('بتاخد', 1), ('حوض', 1), ('بكتريا', 1), ('لترمبنحتاج', 1), ('المسحوبه', 1), ('دنماركي', 1), ('Tweet', 1), ('الامانه', 1), ('الوفا', 1), ('استخف', 1), ('المتضاربه', 1), ('خسارة', 1), ('والسببب', 1), ('سوريااتفاق', 1), ('انظمتها', 1), ('ساخبر', 1), ('ابطات', 1), ('daa', 1), ('با', 1), ('ديمبا', 1), ('Tips', 1), ('مازوم', 1), ('بريسكت', 1), ('ارياس', 1), ('فولكر', 1), ('للالماني', 1), ('للاذاعات', 1), ('الكسندر', 1), ('وفوكسكون', 1), ('امامها', 1), ('وهونغ', 1), ('ديكابيريو', 1), ('bird', 1), ('اوكامبوس', 1), ('نتاج', 1), ('جوبزيلا', 1), ('سندرا', 1), ('تبع', 1), ('السنيد', 1), ('الكمار', 1), ('ريجيكا', 1), ('بيقطع', 1), ('وكوكلان', 1), ('هاربر', 1), ('تايلر', 1), ('بالمانيات', 1), ('للمراقبه', 1), ('ميتييلاند', 1), ('للاسكان', 1), ('رولينج', 1), ('المؤلفه', 1), ('غلاس', 1), ('الاخوين', 1), ('ياماكان', 1), ('وكويار', 1), ('المتسخه', 1), ('باو', 1), ('بافادته', 1), ('شراب', 1), ('باجوبه', 1), ('لاصغر', 1), ('بالبشره', 1), ('غريس', 1), ('للتربيه', 1), ('العشريه', 1), ('الجزائرجدل', 1), ('لاثيوبيا', 1), ('فيرتونخن', 1), ('الضامنه', 1), ('الاباطره', 1), ('المتحدهالادله', 1), ('استشرى', 1), ('اقوالها', 1), ('استشرف', 1), ('الليثيوم', 1), ('كافيين', 1), ('ملليغرام', 1), ('ادراجه', 1), ('للياقه', 1), ('اسنانه', 1), ('وميونخ', 1), ('للاترك', 1), ('للحشمه', 1), ('الاغا', 1), ('قرى', 1), ('كندا', 1), ('لانغ', 1), ('اسبوعي', 1), ('للاجيال', 1), ('بالسوشيال', 1), ('ابومسامح', 1), ('بالغنوشي', 1), ('ناشيونال', 1), ('Gmoji', 1), ('ET', 1), ('تعبس', 1), ('وانسجته', 1), ('للازياء', 1), ('غوتشي', 1), ('بينيلوبي', 1), ('لصياغه', 1), ('افسدته', 1), ('بالاستراتيجيه', 1), ('شراحيلي', 1), ('باكاذيب', 1), ('لاعادتها', 1), ('Boxtrolls', 1), ('الذبحه', 1), ('موستانغ', 1), ('تشيكو', 1), ('الخمسيه', 1), ('فرديناند', 1), ('مكروه', 1), ('عتاب', 1), ('اصداراتهما', 1), ('للدالاي', 1), ('Sniper', 1), ('American', 1), ('افتقاد', 1), ('بويان', 1), ('لالوفاق', 1), ('تويتريا', 1), ('مالكوفيتش', 1), ('نورالشريف', 1), ('يوتيكو', 1), ('الدرايف', 1), ('انغماس', 1), ('هاك', 1), ('دافيرسا', 1), ('القذره', 1), ('سين', 1), ('اخفاءها', 1), ('وفيوري', 1), ('هيرن', 1), ('اخلاقي', 1), ('مترف', 1), ('هرج', 1), ('مستغرب', 1), ('المسكوب', 1), ('تنزل', 1), ('المقالح', 1), ('فكانت', 1), ('المعقمه', 1), ('حيازة', 1), ('الملوخيه', 1), ('محفظة', 1), ('بكونغرس', 1), ('الفيول', 1), ('بخاميس', 1), ('لودوغريتس', 1), ('والارامل', 1), ('بالمحتوي', 1), ('استراتيجيات', 1), ('فانتوم', 1), ('اوي', 1), ('مفروسه', 1), ('لانظمه', 1), ('اربكت', 1), ('البانتومايم', 1), ('موريشوس', 1), ('مشتاق', 1), ('تاديبيه', 1), ('ميني', 1), ('مغضوب', 1), ('وساضم', 1), ('اوليفييه', 1), ('دينش', 1), ('والجبهه', 1), ('بمكتوميناي', 1), ('ابناؤه', 1), ('العبيه', 1), ('التسجيليه', 1), ('سيلتيك', 1), ('المفبركه', 1), ('الرئاسات', 1), ('والامل', 1), ('بشيريهان', 1), ('متصور', 1), ('EasyJet', 1), ('ساخط', 1), ('Design', 1), ('Porsche', 1), ('NOTICE', 1), ('RED', 1), ('منعايدكن', 1), ('بامراه', 1), ('تخافت', 1)]\n",
      "Most common 2-grams:\n",
      "[(('ب', 'مليار'), 427), (('تعرف', 'علي'), 363), (('فيروس', 'كار'), 330), (('صندوق', 'نقد'), 324), (('الصحه', 'العالميه'), 309), (('طير', 'الامارات'), 272), (('سبب', 'كار'), 217), (('لقاح', 'كار'), 206), (('لاول', 'مر'), 197), (('اتحاد', 'الاوروبي'), 187), (('هذا', 'سبب'), 177), (('عاد', 'ال'), 145), (('مانشستر', 'يونايتد'), 144), (('قطاع', 'الخاص'), 142), (('ب', 'مليون'), 136), (('نمو', 'اقتصاد'), 135), (('مطار', 'دب'), 134), (('ل', 'مليار'), 132), (('شرق', 'الاوسط'), 127), (('خلال', 'شهر'), 125), (('توقع', 'نمو'), 124), (('ميز', 'جديد'), 124), (('تعرف', 'على'), 122), (('مانشستر', 'سي'), 122), (('مواجه', 'كار'), 121), (('مليون', 'مسافر'), 118), (('الامم', 'المتحده'), 118), (('محمد', 'رمض'), 117), (('كره', 'قدم'), 115), (('فن', 'مصر'), 114), (('هاتف', 'ذكي'), 113), (('هذه', 'الاسباب'), 106), (('رحلة', 'ال'), 104), (('دور', 'الانجليزي'), 103), (('اتحاد', 'جد'), 102), (('اهلي', 'جد'), 102), (('خطوط', 'السعوديه'), 102), (('اقتصاد', 'عالم'), 100), (('بايرن', 'ميونخ'), 100), (('دور', 'ابطال'), 99), (('فوز', 'علي'), 97), (('كار', '؟'), 97), (('منطق', 'يورو'), 97), (('محمد', 'بن'), 91), (('شركة', 'طير'), 90), (('ال', 'مليار'), 90), (('سناب', 'شاتي'), 90), (('اتحاد', 'طير'), 89), (('أثر', 'علي'), 88), (('بنك', 'دولي'), 87), (('للمره', 'الاولي'), 87), (('علي', 'حساب'), 87), (('عادل', 'امام'), 87), (('حصول', 'علي'), 86), (('منتخب', 'سعودي'), 86), (('سان', 'جيرمان'), 85), (('بيت', 'ابيض'), 85), (('دول', 'خليج'), 85), (('ربع', 'الاول'), 84), (('ال', 'دور'), 82), (('ساعد', 'علي'), 82), (('كاسي', 'عالم'), 82), (('دور', 'الابطال'), 82), (('رئيس', 'وزراء'), 82), (('منظم', 'الصحه'), 81), (('سرطان', 'ثدي'), 81), (('فا', 'فن'), 81), (('فاز', 'جائز'), 81), (('ضغط', 'دم'), 80), (('حزب', 'الله'), 80), (('عبر', 'مطار'), 79), (('مواقع', 'تواصل'), 79), (('قن', 'سويس'), 79), (('تي', 'تو'), 77), (('دور', 'سوبر'), 77), (('مليون', 'سائح'), 76), (('حرب', 'التجاريه'), 76), (('مسافر', 'عبر'), 75), (('هواتف', 'الذكيه'), 73), (('ضد', 'كار'), 71), (('اتفاق', 'تجار'), 70), (('ربع', 'ثالث'), 69), (('عمر', 'دياب'), 68), (('تفوق', 'علي'), 68), (('رد', 'علي'), 67), (('نصف', 'نهائي'), 67), (('هواتف', 'ايفون'), 66), (('خطر', 'الاصابه'), 65), (('عبد', 'عزيز'), 65), (('خبر', 'سار'), 65), (('فل', 'دب'), 65), (('مرض', 'سكر'), 65), (('جديد', 'علي'), 64), (('سوبر', 'الاوروبي'), 64), (('جيش', 'يمن'), 63), (('كور', 'الشماليه'), 63), (('صندوق', 'استثمار'), 63), (('تستانف', 'رحلة'), 63), (('أمد', 'عقد'), 63), (('تغلب', 'علي'), 62), (('اتلتيكو', 'مدريد'), 62), (('استحوذ', 'علي'), 62), (('علي', 'سب'), 61), (('ست', 'هام'), 61), (('نهائي', 'دور'), 61), (('رقم', 'قياس'), 60), (('بن', 'سلم'), 60), (('استوى', 'فيل'), 60), (('صلى', 'ال'), 60), (('ربع', 'نهائي'), 60), (('توقع', 'اتفاق'), 60), (('جبى', 'ان'), 60), (('تامر', 'حسن'), 59), (('مهرج', 'القاهره'), 59), (('ربع', 'ثاني'), 59), (('حافظ', 'علي'), 59), (('خلال', 'عام'), 59), (('حول', 'عالم'), 59), (('زاد', 'خطر'), 58), (('مصر', '؟'), 58), (('باريس', 'سان'), 58), (('دراما', 'رمض'), 58), (('قطاع', 'السياحه'), 58), (('ذكاء', 'اصطناع'), 57), (('سلط', 'عمان'), 57), (('فوز', 'صعب'), 56), (('رحلة', 'الجويه'), 56), (('سمير', 'غانم'), 56), (('شرك', 'طير'), 56), (('جديد', 'سب'), 56), (('وافق', 'علي'), 56), (('ردى', 'علي'), 55), (('ابطال', 'اوروبا'), 55), (('هاتف', 'ايفون'), 55), (('نقد', 'دولي'), 55), (('دور', 'الاوروبي'), 55), (('قادر', 'علي'), 55), (('كار', 'علي'), 54), (('حفاظ', 'علي'), 53), (('اقتصاد', 'سعودي'), 53), (('مصر', 'طير'), 53), (('استثمار', 'الاجنبي'), 53), (('كاسي', 'اوروبا'), 52), (('فنان', 'مصر'), 52), (('حرس', 'ثورة'), 52), (('اصابه', 'جديد'), 52), (('رحلة', 'طير'), 52), (('كاظم', 'ساهر'), 52), (('حصل', 'علي'), 52), (('نتر', 'ميل'), 51), (('علي', 'اندرويد'), 51), (('فيروس', 'زاك'), 51), (('القاهره', 'سينمائي'), 50), (('نانسي', 'عجرم'), 50), (('علن', 'اصابه'), 50), (('زير', 'الماليه'), 50), (('اولمبياد', 'طوكيو'), 50), (('استثمار', 'عامه'), 50), (('نصف', 'الاول'), 50), (('ناتج', 'محل'), 50), (('يم', 'ان'), 50), (('زير', 'مال'), 49), (('نهائي', 'كاسي'), 49), (('لقاح', 'وزر'), 49), (('محمد', 'عبد'), 49), (('موت', 'غاب'), 49), (('أثار', 'جدل'), 49), (('حجر', 'صحة'), 49), (('علي', 'اجهزه'), 49), (('حرب', 'التجاره'), 48), (('عمل', 'علي'), 48), (('الاصابه', 'سرطان'), 48), (('منتخب', 'المانيا'), 48), (('؟', 'دراس'), 48), (('فنادق', 'دب'), 47), (('نظام', 'اندرويد'), 47), (('مليون', 'زائر'), 47), (('ولاية', 'المتحده'), 47), (('فضل', 'لاعب'), 47), (('كثر', 'عرض'), 46), (('علي', 'ايفون'), 46), (('مصر', 'توقع'), 46), (('علي', 'اقتصاد'), 46), (('القيمه', 'المضافه'), 46), (('انضم', 'ال'), 46), (('ال', 'جي'), 45), (('عدد', 'سياح'), 45), (('لي', 'عهد'), 45), (('السعوديه', 'طلق'), 45), (('منظم', 'التجاره'), 45), (('قابل', 'طي'), 45), (('علي', 'تويتر'), 45), (('ال', 'ربع'), 45), (('هيفاء', 'هبة'), 45), (('؟', 'ال'), 44), (('كور', 'الجنوبيه'), 44), (('ميليشيات', 'الحوثي'), 44), (('زمه', 'كار'), 44), (('ندا', 'بارز'), 44), (('ملك', 'سلم'), 44)]\n"
     ]
    }
   ],
   "source": [
    "#Helper Functions\n",
    "def most_common_words(tokenized_text, top_n=200):\n",
    "    words = Counter(tokenized_text)\n",
    "    return words.most_common(top_n)\n",
    "\n",
    "def least_common_words(tokenized_text, bottom_n=200):\n",
    "    words = Counter(tokenized_text)\n",
    "    return words.most_common()[:-bottom_n-1:-1]\n",
    "\n",
    "def most_common_ngrams(tokenized_text, n=2, top_n=200):\n",
    "    ngrams_list = ngrams(tokenized_text, n)\n",
    "    ngrams_count = Counter(ngrams_list)\n",
    "    return ngrams_count.most_common(top_n)\n",
    "\n",
    "word2count = {}\n",
    "\n",
    "for data in text['lemmatized']:  \n",
    "    words = nltk.word_tokenize(data) # Split text into words (tokens)\n",
    "    for word in words:\n",
    "        if word not in word2count:\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "word_count_df = pd.DataFrame(word2count.items(), columns=['Word', 'Count'])\n",
    "\n",
    "# Use auxiliary functions\n",
    "tokenized_text = nltk.word_tokenize(' '.join(text['lemmatized']))  # جمع جميع النصوص\n",
    "print(\"Most common words:\")\n",
    "print(most_common_words(tokenized_text))\n",
    "\n",
    "print(\"Least common words:\")\n",
    "print(least_common_words(tokenized_text))\n",
    "\n",
    "print(\"Most common 2-grams:\")\n",
    "print(most_common_ngrams(tokenized_text, n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caf426e8-c017-4b07-be99-52b9cfd5b2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words (BoW) Matrix:\n",
      "       aa  apple  arab  arabs  bbm  bmw  bollywood  brexit  cia  dna  ...  \\\n",
      "0       0      0     0      0    0    0          0       0    0    0  ...   \n",
      "1       0      0     0      0    0    0          0       0    0    0  ...   \n",
      "2       0      0     0      0    0    0          0       0    0    0  ...   \n",
      "3       0      0     0      0    0    0          0       0    0    0  ...   \n",
      "4       0      0     0      0    0    0          0       0    0    0  ...   \n",
      "...    ..    ...   ...    ...  ...  ...        ...     ...  ...  ...  ...   \n",
      "57782   0      0     0      0    0    0          0       0    0    0  ...   \n",
      "57783   0      0     0      0    0    0          0       0    0    0  ...   \n",
      "57784   0      0     0      0    0    0          0       0    0    0  ...   \n",
      "57785   0      0     0      0    0    0          0       0    0    0  ...   \n",
      "57786   0      0     0      0    0    0          0       0    0    0  ...   \n",
      "\n",
      "       يوم  يونان  يونايتد  يونس  يونغ  يونيسف  يونيسكو  يونيسيف  يونيون  \\\n",
      "0        1      0        0     0     0       0        0        0       0   \n",
      "1        0      0        0     0     0       0        0        0       0   \n",
      "2        0      0        0     0     0       0        0        0       0   \n",
      "3        0      0        0     0     0       0        0        0       0   \n",
      "4        0      0        0     0     0       0        0        0       0   \n",
      "...    ...    ...      ...   ...   ...     ...      ...      ...     ...   \n",
      "57782    0      0        0     0     0       0        0        0       0   \n",
      "57783    0      0        0     0     0       0        0        0       0   \n",
      "57784    0      0        0     0     0       0        0        0       0   \n",
      "57785    0      0        0     0     0       0        0        0       0   \n",
      "57786    0      0        0     0     0       0        0        0       0   \n",
      "\n",
      "       يويفا  \n",
      "0          0  \n",
      "1          0  \n",
      "2          0  \n",
      "3          0  \n",
      "4          0  \n",
      "...      ...  \n",
      "57782      0  \n",
      "57783      0  \n",
      "57784      0  \n",
      "57785      0  \n",
      "57786      0  \n",
      "\n",
      "[57787 rows x 7957 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "text = pd.read_excel(r'C:\\Users\\s7r_2\\Downloads\\��تصنيف الاخبار العربيه - نسخة.xlsx')\n",
    "#Bag of Words (BoW)\n",
    "bow_vectorizer = CountVectorizer(min_df=5)\n",
    "bow_matrix = bow_vectorizer.fit_transform(text['lemmatized'])\n",
    "\n",
    "#Convert to DataFrame for better visualization\n",
    "bow_df = pd.DataFrame(bow_matrix.toarray(), columns=bow_vectorizer.get_feature_names_out())\n",
    "print(\"Bag of Words (BoW) Matrix:\")\n",
    "print(bow_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ec7a044-e2a4-451e-aff2-dd0fddf62897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix shape: (57787, 23529)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create the TfidfVectorizer\n",
    "tfidf_Arabic = TfidfVectorizer()\n",
    "\n",
    "# Apply fit_transform to the data\n",
    "tfidf_matrix = tfidf_Arabic.fit_transform(text['lemmatized'])\n",
    "\n",
    "print(\"TF-IDF Matrix shape:\", tfidf_matrix.shape)\n",
    "with open(\"tfidf_Arabic.pkl\", \"wb\") as tfidf_file:\n",
    "    pickle.dump(tfidf_Arabic,tfidf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a1d041a-8f3d-4a19-bc40-36afa8e070d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.9103651150718117\n",
      "SVM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      اقتصاد       0.89      0.89      0.89      2113\n",
      " التكنولوجيا       0.92      0.91      0.92      1499\n",
      "     السياحة       0.90      0.91      0.91      1029\n",
      "       رياضة       0.98      0.96      0.97      1956\n",
      "       سياسة       0.85      0.85      0.85      1481\n",
      "         صحة       0.89      0.93      0.91      1511\n",
      "          فن       0.92      0.91      0.91      1969\n",
      "\n",
      "    accuracy                           0.91     11558\n",
      "   macro avg       0.91      0.91      0.91     11558\n",
      "weighted avg       0.91      0.91      0.91     11558\n",
      "\n",
      "Naive Bayes Accuracy: 0.8857068697006403\n",
      "Naive Bayes Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      اقتصاد       0.75      0.95      0.84      2113\n",
      " التكنولوجيا       0.94      0.87      0.90      1499\n",
      "     السياحة       0.95      0.71      0.81      1029\n",
      "       رياضة       0.96      0.96      0.96      1956\n",
      "       سياسة       0.90      0.76      0.82      1481\n",
      "         صحة       0.91      0.91      0.91      1511\n",
      "          فن       0.90      0.93      0.91      1969\n",
      "\n",
      "    accuracy                           0.89     11558\n",
      "   macro avg       0.90      0.87      0.88     11558\n",
      "weighted avg       0.89      0.89      0.89     11558\n",
      "\n",
      "Random Forest Accuracy: 0.850147084270635\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      اقتصاد       0.84      0.85      0.84      2113\n",
      " التكنولوجيا       0.90      0.86      0.88      1499\n",
      "     السياحة       0.88      0.86      0.87      1029\n",
      "       رياضة       0.92      0.92      0.92      1956\n",
      "       سياسة       0.81      0.74      0.77      1481\n",
      "         صحة       0.81      0.86      0.84      1511\n",
      "          فن       0.80      0.84      0.82      1969\n",
      "\n",
      "    accuracy                           0.85     11558\n",
      "   macro avg       0.85      0.85      0.85     11558\n",
      "weighted avg       0.85      0.85      0.85     11558\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X = tfidf_matrix\n",
    "y = text['صنف الخبر'] \n",
    "\n",
    "#Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix, y, test_size=0.2, random_state=42)  #Split data\n",
    "\n",
    "#Function to evaluate model performance\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    predictions = model.predict(X_test)  #Make predictions\n",
    "    accuracy = accuracy_score(y_test, predictions)  #Calculate accuracy\n",
    "    report = classification_report(y_test, predictions)  #Generate classification report\n",
    "    return accuracy, report\n",
    "\n",
    "svm_model = SVC(kernel='linear', class_weight='balanced')  #Initialize SVM model with linear kernel and class weights\n",
    "svm_model.fit(X_train, y_train)  #Train the model\n",
    "svm_accuracy, svm_report = evaluate_model(svm_model, X_test, y_test)  #Evaluate SVM\n",
    "print(\"SVM Accuracy:\", svm_accuracy)  #Print accuracy\n",
    "print(\"SVM Classification Report:\\n\", svm_report)  #Print classification report\n",
    "\n",
    "nb_model = MultinomialNB()  #Initialize Naive Bayes model\n",
    "nb_model.fit(X_train, y_train)  #Train the model\n",
    "nb_accuracy, nb_report = evaluate_model(nb_model, X_test, y_test)  #Evaluate Naive Bayes\n",
    "print(\"Naive Bayes Accuracy:\", nb_accuracy)  #Print accuracy\n",
    "print(\"Naive Bayes Classification Report:\\n\", nb_report)  #Print classification report\n",
    "\n",
    "rf_model = RandomForestClassifier(class_weight='balanced', random_state=42)  #Initialize Random Forest model with class weights\n",
    "rf_model.fit(X_train, y_train)  #Train the model\n",
    "rf_accuracy, rf_report = evaluate_model(rf_model, X_test, y_test)  #Evaluate Random Forest\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)  #Print accuracy\n",
    "print(\"Random Forest Classification Report:\\n\", rf_report)  #Print classification report\n",
    "with open(\"model_Arabic.pickle\", \"rb\") as model_file:\n",
    "    lg_model = pickle.load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8553e71a-cc11-4a79-9d5e-1504e9bfe83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted category is: اقتصاد\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Data processing function\n",
    "def preprocess_data(text):\n",
    "    text = text.lower()  # تحويل النص إلى حروف صغيرة\n",
    "    text = re.sub(r'[^\\w\\s\\'\\\"]', '', text)  # إزالة علامات الترقيم\n",
    "    return text\n",
    "\n",
    "# Load data\n",
    "text = text[text['lemmatized'].notnull() & (text['lemmatized'] != '')]\n",
    "\n",
    "# Data processing\n",
    "text['lemmatized'] = text['lemmatized'].apply(preprocess_data)\n",
    "\n",
    "# Create a TF-IDF matrix\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=5)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(text['lemmatized'])\n",
    "\n",
    "X = tfidf_matrix\n",
    "y = text['صنف الخبر']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train logistic regression model\n",
    "lg_model = LogisticRegression(max_iter=200, verbose=1)\n",
    "lg_model.fit(X_train, y_train)\n",
    "\n",
    "# Store the form and TF-IDF\n",
    "with open(\"tfidf_Arabic.pkl\", \"rb\") as tfidf_file:\n",
    "    tfidf_Arabic = pickle.load(tfidf_file)\n",
    "with open(\"model_Arabic.pickle\", \"rb\") as model_file:\n",
    "    svm_model_ar = pickle.load(model_file)\n",
    "\n",
    "# Prediction function\n",
    "def predict_category(text):\n",
    "    cleaned_text = preprocess_data(text)  # معالجة النص\n",
    "    tfidf_data = tfidf_vectorizer.transform([cleaned_text])  # تحويل النص إلى تمثيل TF-IDF\n",
    "    prediction = lg_model.predict(tfidf_data)  # إجراء التنبؤ\n",
    "    return prediction[0]  # إرجاع الفئة المتوقعة\n",
    "\n",
    "# New text class prediction\n",
    "new_text = \"وزير مالية لبنان:إجراءات تقشفية استثنائية بموازنة 2019\"\n",
    "predicted_category = predict_category(new_text)\n",
    "print(f\"The predicted category is: {predicted_category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46c926c1-db76-4caa-9754-bf44c87ea276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "\n",
    "# Load the model and TF-IDF Vectorizer\n",
    "#Arabic\n",
    "with open(\"tfidf_Arabic.pkl\", \"rb\") as tfidf_file:\n",
    "    tfidf_Arabic = pickle.load(tfidf_file)\n",
    "with open(\"model_Arabic.pickle\", \"rb\") as model_file:\n",
    "    svm_model_ar = pickle.load(model_file)\n",
    "\n",
    "# Text preprocessing function\n",
    "def preprocess_data(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s\\'\\\"]', '', text)\n",
    "    return text\n",
    "\n",
    "# Classification function using the loaded model\n",
    "def predict_category(text):\n",
    "    cleaned_text = preprocess_data(text)  # Text processing\n",
    "    tfidf_data = tfidf_Arabic.transform([cleaned_text])  # Convert text to TF-IDF representation\n",
    "    prediction = svm_model_ar.predict(tfidf_data)  # Make a prediction\n",
    "    return prediction[0]  # Returns the expected class\n",
    "\n",
    "\n",
    "# Function to classify text and show the result\n",
    "def classify_text():\n",
    "    text = entry.get()\n",
    "    if not text.strip():\n",
    "        messagebox.showwarning(\"خطأ\", \"الرجاء إدخال نص للتصنيف!\")\n",
    "        return\n",
    "    category = predict_category(text)\n",
    "    result_label.config(text=f\"نوع الخبر : {category}\")\n",
    "\n",
    "# Function to clear text\n",
    "def clear_text():\n",
    "    entry.delete(0, tk.END)\n",
    "    result_label.config(text=\"\")\n",
    "\n",
    "# Set up the main GUI window\n",
    "root = tk.Tk()\n",
    "root.geometry(\"800x500\")\n",
    "root.title(\"تصنيف الأخبارالعربيه\")\n",
    "\n",
    "# Setting items in the user interface\n",
    "label1 = tk.Label(root, text=\"محلل تصنيف الأخبار\", font=(\"Helvetica\", 14))\n",
    "label1.pack(pady=10)\n",
    "\n",
    "label2 = tk.Label(root, text=\"أدخل النص:\", font=(\"Helvetica\", 12))\n",
    "label2.pack(pady=5)\n",
    "\n",
    "entry = tk.Entry(root, font=(\"Helvetica\", 12), width=50)\n",
    "entry.pack(pady=5)\n",
    "\n",
    "classify_button = tk.Button(root, text=\"تصنيف\", command=classify_text, font=(\"Helvetica\", 12), bg=\"#002179\", fg=\"white\")\n",
    "classify_button.pack(pady=10)\n",
    "\n",
    "clear_button = tk.Button(root, text=\"مسح النص\", command=clear_text, font=(\"Helvetica\", 12), bg=\"#d9534f\", fg=\"white\")\n",
    "clear_button.pack(pady=5)\n",
    "\n",
    "result_label = tk.Label(root, text=\"\", font=(\"Helvetica\", 16), fg=\"blue\")\n",
    "result_label.pack(pady=20)\n",
    "\n",
    "# Run the GUI application\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be836baf-955c-4e39-8f8a-3847349d9288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a92c22-2480-4b5d-a710-26b257b800f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
